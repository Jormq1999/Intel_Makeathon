# AI-Friendly Feedback for `06-validation-document-format.md`

**Source Repository:** `/nfs/site/disks/juanpsal_disk_002/iscp-fst/ip-csme`

## 1. Analysis Summary

While the `ip-csme` repository does not contain Markdown-based validation documents, it does have a clear structure for tests and a test plan in `CSME_USBR_COVERAGE_XLS.xlsx`. This provides a strong foundation for defining a standardized, AI-consumable format for test plans.

The goal is to create a Markdown format that is both human-readable and easily parsable by an AI agent. This allows the agent to understand the intent of a test, and in the future, to automatically generate or update these documents.

## 2. Proposed Test Plan Markdown Format

A new test plan should be created for each major feature or for a set of related tests generated by the AI agent.

**File Location:** `verif/csme_usbr/tests/<test_name>/<test_name>_test_plan.md`
**Example:** `verif/csme_usbr/tests/moa_usbr_ai_dma_error_test/moa_usbr_ai_dma_error_test_plan.md`

### Test Plan Template

```markdown
# Test Plan: {{Test Name}}

**Author:** AI Test Generation Agent
**Date:** {{Generation Date}}
**Related Test File:** `{{Test File Name}}`

---

## 1. Test Objective

A clear, concise statement describing the primary goal of this test. This section answers the question: "What is this test trying to verify?"

*Example: To verify that the DUT correctly handles a DMA data corruption error during a bulk IN transaction.*

---

## 2. Test Description

A more detailed description of the test scenario. This should outline the sequence of events that will occur during the test.

*Example:
1.  Initialize the DUT and configure a bulk IN endpoint.
2.  Start a bulk IN transaction sequence.
3.  Use a driver-level callback or sequence-level override to corrupt a byte in the data payload being sent from the device model to the DUT.
4.  Monitor the DUT's interrupt status register to verify that the appropriate error flag is asserted.
5.  Check that the scoreboard reports a data mismatch for the corrupted transaction.*

---

## 3. Configuration

This section details the specific UVM configuration required for this test. It should be formatted as a table for easy parsing.

| Configuration Parameter | Value / Constraint | Rationale |
| ----------------------- | ------------------ | --------- |
| `m_cfg.num_dma_trans`   | 1                  | Focus on a single DMA transaction for clarity. |
| `m_cfg.enable_error_inj`| 1'b1               | Enable the error injection mechanism in the agent. |
| `m_cfg.error_type`      | `DMA_CORRUPTION`   | Specify the exact type of error to be injected. |

---

## 4. Stimulus Details

Describes the key sequences and transactions involved in the test.

-   **Top-Level Sequence:** `csme_usbr_ai_dma_error_seq`
-   **Key Sub-Sequences:**
    -   `csme_usbr_init_seq`: Standard DUT initialization.
    -   `csme_usbr_bulk_data_seq`: The main data transaction sequence. This will be run with a callback to inject the error.
-   **Transaction Constraints:**
    -   The `bulk_data_transaction` will be constrained to have a `data_length` > 256 bytes.

---

## 5. Coverage Goals

Lists the specific functional coverage points this test is designed to hit. This is the most critical section for AI-driven coverage closure.

| Covergroup Name | Coverpoint / Cross | Target Bin |
| --------------- | ------------------ | ---------- |
| `dma_cg`        | `error_type_cp`    | `CORRUPT_DATA` |
| `dma_cg`        | `trans_type_cp`    | `BULK_IN` |
| `dma_error_cross`| `error_type_cp` x `trans_type_cp` | (`CORRUPT_DATA`, `BULK_IN`) |

---

## 6. Expected Results

A description of the expected outcome.

-   The DUT should assert the `dma_error` interrupt.
-   The scoreboard should report one failed transaction.
-   The simulation should terminate without any UVM errors (other than the expected scoreboard error).
-   The coverage goals listed above should be met.
```

## 3. AI Agent Integration

-   **Generation:** When the AI agent generates a new test, it should also generate the corresponding `_test_plan.md` file and fill in the placeholders (`{{...}}`).
-   **Parsing:** When analyzing existing tests, the agent should look for these Markdown files to quickly understand the purpose and coverage goals of each test, rather than having to parse the SystemVerilog code from scratch every time.
-   **Reporting:** After a test run, the agent could potentially update this document with the results, such as whether the coverage goals were met and if the test passed or failed.
